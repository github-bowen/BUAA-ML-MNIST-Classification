# Image Classification on MNIST Dataset Using SVM

[中文版](./README_zh)

[TOC]

## Project Introduction

This project uses the `sklearn.svm.SVC` model provided by the sklearn toolkit for training, and the dataset is the [MNIST dataset](http://yann.lecun.com/exdb/mnist/).

The five training code files in the `train` directory reflect the process of tuning the SVM hyperparameters. (See below for **training process**)

Finally, the optimal model achieved an accuracy of **97.79%** on the test set.

## Project Directory Structure

The project directory is as follows:

```python
.
├── data
│   ├── t10k-images.idx3-ubyte
│   ├── t10k-labels.idx1-ubyte
│   ├── train-images.idx3-ubyte
│   └── train-labels.idx1-ubyte
├── models  # models in this directory could be generated by running training files in `train` directory.
│   ├── svm_model1.pkl
│   ├── svm_model2.pkl
│   ├── svm_model3.pkl
│   ├── svm_model4.pkl
│   ├── svm_model5.pkl
│   ├── transfer1.pkl
│   ├── transfer2.pkl
│   ├── transfer3.pkl
│   ├── transfer4.pkl
│   └── transfer5.pkl
├── README.md
├── test.py
└── train
    ├── train1.ipynb
    ├── train2.ipynb
    ├── train3.ipynb
    ├── train4.ipynb
    └── train5.ipynb
```

Among them:

- The `data` directory stores the MNIST dataset (decompressed) downloaded from the [data address](http://yann.lecun.com/exdb/mnist/) in the assignment requirements.

- The `models` directory stores the trained models. There are a total of 5 groups of models in this directory, corresponding to five training code files (`train/train{i}.ipynb`, i is 1-5). For the i-th group of models, `svm_model{i}.pkl` is the saved SVM model.

  > Note: Since the feature values are first standardized using *StandardScaler* in the training code, the feature values of the test data also need to be standardized in the same way when testing the code, so you need to save the corresponding standardization model `transfer{i}.pkl`.

- The `train` directory stores 5 groups of model training codes, all in *ipynb* format. Therefore, you need to install jupyter related dependencies to run the training code. For specific installation methods, see **Environment Configuration**.

- `test.py` test code, which can be used from the command line. For specific usage methods, see below.

## Environment Configuration

If you do not need to run the training program (`train/train{i}.ipynb`), run:

```bash
pip install scikit-learn, numpy, joblib
```

If you want to run the training program, run:

```bash
pip install scikit-learn, numpy, joblib, jupyter
```

## Code Execution

### Train Model

Open *ipynb* files under `train` directory and run all cells. The generated models will be saved in `models` directory.

### Test Model

Open terminal or command and run one of the following commands:

- Test one of 5 models:

  ```shell
  python test.py $model_number
  ```

  Where:

  `$model_number` is the model number, which can be [1, 2, 3, 4, 5].

- Test all models:

  ```shell
  python test.py all
  ```

## Test Results

Run `python test.py all` in ipython to test all models:

```
>ipython
Python 3.8.16 (default, Jan 17 2023, 22:25:28) [MSC v.1916 64 bit (AMD64)]
Type 'copyright', 'credits' or 'license' for more information
IPython 8.8.0 -- An enhanced Interactive Python. Type '?' for help.

In [1]: import warnings

In [2]: warnings.filterwarnings('ignore', category=UserWarning)

In [3]: %run test.py all
Start testing model svm_model1:
        Model: SVC(C=10, kernel='poly', max_iter=1000, probability=True)
        Model parameters:  {'C': 10, 'gamma': 'scale', 'kernel': 'poly'}
        Predicted values:  [7 2 1 ... 4 5 6]
        True values:  [7 2 1 ... 4 5 6]
        Direct comparison of true values and predicted values:  [ True  True  True ...  True  True  True]
        Accuracy:  0.9717
Model svm_model1 testing completed!

Start testing model svm_model2:
        Model: SVC(C=13, kernel='poly', max_iter=1000, probability=True)
        Model parameters:  {'C': 13}
        Predicted values:  [7 2 1 ... 4 5 6]
        True values:  [7 2 1 ... 4 5 6]
        Direct comparison of true values and predicted values:  [ True  True  True ...  True  True  True]
        Accuracy:  0.9739
Model svm_model2 testing completed!

Start testing model svm_model3:
        Model: SVC(C=19, kernel='poly', max_iter=1000, probability=True)
        Model parameters:  {'C': 19}
        Predicted values:  [7 2 1 ... 4 5 6]
        True values:  [7 2 1 ... 4 5 6]
        Direct comparison of true values and predicted values:  [ True  True  True ...  True  True
True]
        Accuracy:   0.9745
Model svm_model3 testing completed!

Start testing model svm_model4:
        Model: SVC(C=20, kernel='poly', max_iter=5000, probability=True)
        Model parameters: {'C':20}
        Predicted values: [7 2 1 ... 4 5 6]
        True values: [7 2 1 ... 4 5 6]
        Direct comparison of true values and predicted values: [True True True ... True True True]
        Accuracy:   0.9779
Model svm_model4 testing completed!

Start testing model svm_model5:
        Model: SVC(C=30, kernel='poly', max_iter=5000, probability=True)
        Model parameters: {'C':30}
        Predicted values: [7 2 1 ... 4 5 6]
        True values: [7 2 1 ... 4 5 6]
        Direct comparison of true values and predicted values: [True True True ... True True True]
        Accuracy:   0.9779
Model svm_model5 testing completed!
```

The best models are `svm_model4` and `svm_model5`, with an accuracy of **97.79%** on the test set.

## Training Process

### Model 1

For `sklearn.svm.SVC`, I started with the following parameters for grid search and cross validation:

```python
# SVM classifier
svm_model1 = SVC(probability=True, max_iter=1000)

# Grid search and cross validation
param_dict = {
    'C': [0.1, 1, 10],
    'kernel': ['linear', 'rbf', 'poly'],
    'gamma': ['scale', 'auto']
}
svm_model1 = GridSearchCV(svm_model1, param_dict, n_jobs=-1, cv=2)
```

After training, the optimal model parameters on the training set after cross validation are obtained (they will also be output after running the test code):

```python
Model: SVC(C=10, kernel='poly', max_iter=1000, probability=True)
Model parameters:  {'C': 10, 'gamma': 'scale', 'kernel': 'poly'}
```

The accuracy on the test set is: 0.9717

### Model 2

On the basis of model one, further adjust the range of grid search and cross validation (only adjust the penalty coefficient C from now on):

```python
# SVM classifier
svm_model2 = SVC(C=10, kernel='poly', max_iter=1000, gamma='scale', probability=True)

# Grid search and cross validation
param_dict = {
    'C': [7, 8, 9, 10, 11, 12, 13],
     # 'kernel': ['linear', 'rbf', 'poly'],
     # 'gamma': ['scale', 'auto']
}
svm_model2 = GridSearchCV(svm_model2, param_dict, n_jobs=-1, cv=2)
```

After training, the optimal model parameters on the training set after cross validation are obtained (they will also be output after running the test code):

```python
Model: SVC(C=13, kernel='poly', max_iter=1000, probability=True)
Model parameters:  {'C': 13}
```

The accuracy on the test set is: 0.9739

### Model 3

Grid search and cross validation range:

```python
# SVM classifier
svm_model3 = SVC(kernel='poly', max_iter=1000, gamma='scale', probability=True)

# Grid search and cross validation
param_dict = {
    'C': [13, 15, 17, 19, 21],
     # 'kernel': ['linear', 'rbf', 'poly'],
     # 'gamma': ['scale', 'auto']
}
svm_model3 = GridSearchCV(svm_model3, param_dict, n_jobs=-1, cv=2)
```

After training, the optimal model parameters on the training set after cross validation are obtained (they will also be output after running the test code):

```python
Model: SVC(C=19, kernel='poly', max_iter=1000, probability=True)
Model parameters:  {'C': 19}
```

The accuracy on the test set is: 0.9745

### Model 4

Grid search and cross validation range:

```python
# SVM classifier
svm_model4 = SVC(kernel='poly', max_iter=5000, gamma='scale', probability=True)

# Grid search and cross validation
param_dict = {
    'C': [18, 18.5, 19, 19.5, 20],
     # 'kernel': ['linear', 'rbf', 'poly'],
     # 'gamma': ['scale', 'auto']
}
svm_model4 = GridSearchCV(svm_model4, param_dict, n_jobs=-1, cv=2)
```

After training, the optimal model parameters on the training set after cross validation are obtained (they will also be output after running the test code):

```python
Model: SVC(C=20, kernel='poly', max_iter=5000, probability=True)
Model parameters:  {'C': 20}
```

The accuracy on the test set is: 0.9779

### Model 5

Grid search and cross validation range:

```python
# SVM classifier
svm_model5 = SVC(kernel='poly', max_iter=5000, gamma='scale', probability=True)

# Grid search and cross validation
param_dict = {
    'C': [20, 22, 24, 26, 28, 30, 32],
     # 'kernel': ['linear', 'rbf', 'poly'],
     # 'gamma': ['scale', 'auto']
}
svm_model5 = GridSearchCV(svm_model5, param_dict, n_jobs=-1, cv=2)
```

After training, the optimal model parameters on the training set after cross validation are obtained (they will also be output after running the test code):

```python
Model: SVC(C=30, kernel='poly', max_iter=5000, probability=True)
Model parameters:  {'C': 30}
```

The accuracy on the test set is: 0.9779
