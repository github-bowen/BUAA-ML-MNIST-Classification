{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DATA_PATH = '../data'\n",
    "IMAGE_SIZE = 784  # 28 * 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_mnist(path, kind='train'):\n",
    "    \"\"\"\n",
    "    'train-images-idx3-ubyte.gz', 'train-labels-idx1-ubyte.gz',\n",
    "    't10k-images-idx3-ubyte.gz', 't10k-labels-idx1-ubyte.gz'\n",
    "    Before use, you need to download the above four files to the `path` directory and unzip them\n",
    "    \"\"\"\n",
    "    labels_path = os.path.join(path, '%s-labels.idx1-ubyte' % kind)\n",
    "    images_path = os.path.join(path, '%s-images.idx3-ubyte' % kind)\n",
    "\n",
    "    with open(labels_path, 'rb') as label_file:\n",
    "        labels = np.frombuffer(label_file.read(), dtype=np.uint8, offset=8)\n",
    "\n",
    "    with open(images_path, 'rb') as image_file:\n",
    "        images = np.frombuffer(image_file.read(), dtype=np.uint8,\n",
    "                               offset=16).reshape(len(labels), IMAGE_SIZE)\n",
    "\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read MNIST dataset\n",
    "x_train, y_train = load_mnist(DATA_PATH, kind='train')\n",
    "# x_test, y_test = load_mnist(DATA_PATH, kind='t10k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering: Standardization\n",
    "transfer2 = StandardScaler()\n",
    "x_train = transfer2.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train = x_train[:1000]\n",
    "# y_train = y_train[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# SVM classifier\n",
    "svm_model2 = SVC(C=10, kernel='poly', max_iter=1000, gamma='scale', probability=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Grid search and cross validation\n",
    "param_dict = {\n",
    "    'C': [7, 8, 9, 10, 11, 12, 13],\n",
    "     # 'kernel': ['linear', 'rbf', 'poly'],\n",
    "     # 'gamma': ['scale', 'auto']\n",
    "}\n",
    "svm_model2 = GridSearchCV(svm_model2, param_dict, n_jobs=-1, cv=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Train model\n",
    "svm_model2.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Results of hyperparameter tuning on training data\n",
    "print(\"Best parameters: \\n\", svm_model2.best_params_)\n",
    "print(\"Best results (results in the validation set): \\n\", svm_model2.best_score_)\n",
    "print(\"Best estimator: \\n\", svm_model2.best_estimator_)\n",
    "print(\"Cross-validation results.: \\n\", svm_model2.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Save model\n",
    "joblib.dump(svm_model2, '../models/svm_model2.pkl')\n",
    "# Save StandardScaler\n",
    "joblib.dump(transfer2, '../models/transfer2.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow-py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
